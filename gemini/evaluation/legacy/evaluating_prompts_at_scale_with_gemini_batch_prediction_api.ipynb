{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hztiLWXYHkhZ"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZ0mZ5Hg8_M"
      },
      "source": [
        "# Evaluating prompts at scale with Gemini Batch Prediction API\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fevaluation%2Fevaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/evaluation/evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T90FYh6-htfF"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Ariel Jassan](https://github.com/arieljassan) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKSYzhrTOCBG"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This tutorial guides you through the process of evaluating the effectiveness of your prompts at scale using the Gemini Batch Prediction API via Vertex AI. Even though in this tutorial we will do image classification, it can be extended to other cases as well. One of the benefits of using the Gemini Batch Prediction API is that you can evaluate your prompts and setup in Gemini using hundreds of examples with one single request.\n",
        "\n",
        "You can find more information about the Gemini Batch Prediction API [here](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/batch-prediction-api).\n",
        "\n",
        "For the purpose of this tutorial, we will execute a prompt to classify images into classes of sports. The data is based on an excerpt of the dataset that can be found in https://www.kaggle.com/datasets/gpiosenka/sports-classification.\n",
        "\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. **Prepare the data in BigQuery and GCS**\n",
        "    * Upload sample images to Google Cloud Storage and create ground truth table in BigQuery.\n",
        "    \n",
        "2. **Run Gemini Batch Prediction API**\n",
        "    * Send prompts to Gemini for batch prediction and get results in BigQuery.\n",
        "\n",
        "3. **Analyze results in BigQuery and Looker Studio**\n",
        "    * Present findings, focusing on prompt/dataset strengths and weaknesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQX5j8RYJEXs"
      },
      "source": [
        "## Getting started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOgj6IyiJVkV"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sCnE9GIUkts"
      },
      "outputs": [],
      "source": [
        "! pip install google-cloud-aiplatform --upgrade -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9nGCMsxJZ_v"
      },
      "source": [
        "### Restart Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIWOo23oVGmV"
      },
      "outputs": [],
      "source": [
        "# You will see a notification of Colab crashing. It is the expected behavior.\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Z7Y63KJelC"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV7jgeu9VImB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-FTvlzlJ8lY"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDVVYzTISvGv"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"your-project-id\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Generative model.\n",
        "MODEL_ID = \"gemini-1.5-flash-001\"\n",
        "\n",
        "# BigQuery tables.\n",
        "BQ_DATASET_ID = \"gemini_batch_predictions\"\n",
        "BQ_DATASET = f\"{PROJECT_ID}.{BQ_DATASET_ID}\"\n",
        "FILES_TABLE = f\"{BQ_DATASET_ID}.sports_files\"\n",
        "PROMPTS_TABLE = f\"{BQ_DATASET}.temp_prompts\"\n",
        "TEXT_GENERATION_TABLE_PREFIX = f\"{BQ_DATASET}.results\"\n",
        "\n",
        "# BigQuery views.\n",
        "RESULTS_VIEW = f\"{BQ_DATASET}.extraction_results\"\n",
        "EVALUATION_VIEW = f\"{BQ_DATASET}.evaluation\"\n",
        "\n",
        "# File containing ground truth data in GCS.\n",
        "BUCKET_NAME = \"github-repo\"\n",
        "FOLDER = \"generative-ai/gemini/evaluation/sports_files\"\n",
        "SPORTS_FILE = \"sports_files.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WePqYxwP4L6y"
      },
      "source": [
        "### Import libraries and initialize clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUxxhafP4KM9"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import datetime\n",
        "import json\n",
        "import time\n",
        "from typing import Any, List\n",
        "\n",
        "import bigframes.pandas as bpd\n",
        "from google.cloud import bigquery, storage\n",
        "import vertexai\n",
        "from vertexai.batch_prediction._batch_prediction import BatchPredictionJob\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# BigQuery client.\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Google Cloud Storage client.\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Initialize Vertex AI SDK.\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Set BigQuery Pandas options.\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = LOCATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwhKPE19djbK"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "In this section we will create the dataset in BigQuery, load the table with ground truth, and create the views that will serve for analysis of the results from Gemini and reporting in Looker Studio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOKg8sxIZnzm"
      },
      "source": [
        "### Create BigQuery dataset and load table with ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjWGl6V9ZvhV"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset_id: str, location: str) -> None:\n",
        "    \"\"\"Creates a BigQuery dataset in a location.\"\"\"\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = location\n",
        "\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"Created dataset {bq_client.project}.{dataset.dataset_id}\")\n",
        "\n",
        "\n",
        "def load_files_table_from_uri(files_table: str, uri: str) -> None:\n",
        "    \"\"\"Load ground truth into a BigQuery table from a GCS URI.\"\"\"\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        schema=[\n",
        "            bigquery.SchemaField(\"path\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"label\", \"STRING\"),\n",
        "        ],\n",
        "        skip_leading_rows=1,\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "    )\n",
        "    load_job = bq_client.load_table_from_uri(uri, files_table, job_config=job_config)\n",
        "    load_job.result()\n",
        "\n",
        "    destination_table = bq_client.get_table(files_table)\n",
        "    print(f\"Loaded {destination_table.num_rows} rows.\")\n",
        "\n",
        "\n",
        "create_dataset(dataset_id=BQ_DATASET, location=LOCATION)\n",
        "load_files_table_from_uri(\n",
        "    files_table=FILES_TABLE, uri=f\"gs://{BUCKET_NAME}/{FOLDER}/{SPORTS_FILE}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW4EngZRLlts"
      },
      "source": [
        "### Test image URIs are retrieved from BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRgVfFZIN7ae"
      },
      "outputs": [],
      "source": [
        "ground_truth_df = bpd.read_gbq(FILES_TABLE)\n",
        "images_uri = [row[\"path\"] for _, row in ground_truth_df.iterrows()]\n",
        "print(images_uri[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn2t64pkbQHq"
      },
      "source": [
        "## Define prompt and execute it via Vertex AI Gemini Batch Prediction API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbq75NqxRXBO"
      },
      "source": [
        "### Define the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk-EpTp0uJR4"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\\\n",
        "- Classify the sport from the image below in one of the following categories:\n",
        "* baseball\n",
        "* basketball\n",
        "* tennis\n",
        "* volleyball\n",
        "\n",
        "- Provide an answer in JSON format. 3. Example response:\n",
        "'{\"sport\": \"baseball\"}'\n",
        "\n",
        "- Image:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCGQhmmSRbgc"
      },
      "source": [
        "### Classify one image using the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kchsx7bdrGgf"
      },
      "outputs": [],
      "source": [
        "def download_blob_into_memory(bucket_name: str, blob_name: str) -> Any:\n",
        "    \"\"\"Downloads a blob from GCS into memory.\"\"\"\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    blob = bucket.blob(blob_name)\n",
        "    contents = blob.download_as_bytes()\n",
        "    return contents\n",
        "\n",
        "\n",
        "def classify_image(model_id: str, prompt: str, bucket_name: str, blob_name: str) -> str:\n",
        "    \"\"\"Classifies an image.\"\"\"\n",
        "    model = GenerativeModel(model_id)\n",
        "    contents = download_blob_into_memory(bucket_name, blob_name)\n",
        "    encoded_image = base64.b64encode(contents).decode(\"utf-8\")\n",
        "    image_content = Part.from_data(\n",
        "        data=base64.b64decode(encoded_image), mime_type=\"image/jpeg\"\n",
        "    )\n",
        "    contents = [prompt, image_content]\n",
        "    return model.generate_content(contents)\n",
        "\n",
        "\n",
        "blob_name = ground_truth_df.iloc[0][\"path\"]\n",
        "response = classify_image(\n",
        "    model_id=MODEL_ID,\n",
        "    prompt=prompt,\n",
        "    bucket_name=BUCKET_NAME,\n",
        "    blob_name=f\"{FOLDER}/{blob_name}\",\n",
        ")\n",
        "print(f\"blob_name: {blob_name}\")\n",
        "print(f\"response: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q79hx4JINXZh"
      },
      "source": [
        "### Create a New Line JSON file applying the prompt to each of the images and upload to a BigQuery table\n",
        "In this section, also an `evaluation_id` variable is created to identify the execution run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Dn4SStFOBak"
      },
      "outputs": [],
      "source": [
        "def create_newline_json_file(\n",
        "    prompt: str,\n",
        "    evaluation_ts: str,\n",
        "    evaluation_id: str,\n",
        "    file_name: str,\n",
        "    bucket_name: str,\n",
        "    folder: str,\n",
        "    images_uri: List[str],\n",
        ") -> None:\n",
        "    \"\"\"Creates a newline delimited JSON file.\"\"\"\n",
        "    with open(file_name, \"w\") as outfile:\n",
        "        for image_uri in images_uri:\n",
        "            contents = download_blob_into_memory(bucket_name, f\"{folder}/{image_uri}\")\n",
        "            encoded_image = base64.b64encode(contents).decode(\"utf-8\")\n",
        "            request = {\n",
        "                \"contents\": [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"parts\": [\n",
        "                            {\"text\": prompt},\n",
        "                            {\n",
        "                                \"inlineData\": {\n",
        "                                    \"mimeType\": \"image/jpeg\",\n",
        "                                    \"data\": encoded_image,\n",
        "                                }\n",
        "                            },\n",
        "                        ],\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "            line = {\n",
        "                \"evaluation_ts\": evaluation_ts,\n",
        "                \"evaluation_id\": evaluation_id,\n",
        "                \"prompt_text\": prompt,\n",
        "                \"gcs_uri\": image_uri,\n",
        "                \"request\": request,\n",
        "            }\n",
        "\n",
        "            outfile.write(json.dumps(line))\n",
        "            outfile.write(\"\\n\")\n",
        "\n",
        "\n",
        "def upload_newline_json_file(json_file_name: str, prompts_table: str) -> None:\n",
        "    \"\"\"Uploads a newline delimited JSON file to BigQuery.\"\"\"\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        schema=[\n",
        "            bigquery.SchemaField(\"evaluation_ts\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"evaluation_id\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"prompt_text\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"request\", \"JSON\"),\n",
        "        ],\n",
        "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "    )\n",
        "\n",
        "    with open(json_file_name, \"rb\") as source_file:\n",
        "        job = bq_client.load_table_from_file(\n",
        "            source_file, PROMPTS_TABLE, job_config=job_config\n",
        "        )\n",
        "\n",
        "    job.result()\n",
        "    table = bq_client.get_table(prompts_table)\n",
        "    print(\n",
        "        f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to \"\n",
        "        f\"{prompts_table}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Use current time as identifier of the evaluation.\n",
        "now = datetime.datetime.now()\n",
        "evaluation_id = f\"{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}\"\n",
        "json_file_name = f\"/tmp/{evaluation_id}.json\"\n",
        "\n",
        "# Get URIs of the images from the ground truth table in BigQuery.\n",
        "ground_truth_df = bpd.read_gbq(FILES_TABLE)\n",
        "images_uri = [row[\"path\"] for _, row in ground_truth_df.iterrows()]\n",
        "\n",
        "create_newline_json_file(\n",
        "    prompt=prompt,\n",
        "    evaluation_ts=str(now),\n",
        "    evaluation_id=evaluation_id,\n",
        "    file_name=json_file_name,\n",
        "    bucket_name=BUCKET_NAME,\n",
        "    folder=FOLDER,\n",
        "    images_uri=images_uri,\n",
        ")\n",
        "upload_newline_json_file(json_file_name=json_file_name, prompts_table=PROMPTS_TABLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LveMID56Ngo6"
      },
      "source": [
        "### Launch a Gemini Batch Prediction request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAe5v1N1TOw1"
      },
      "outputs": [],
      "source": [
        "# Define table to store results from Gemini Batch Prediction.\n",
        "text_generation_table = f\"{TEXT_GENERATION_TABLE_PREFIX}_{evaluation_id}\"\n",
        "\n",
        "# Create batch prediction job.\n",
        "batch_job = BatchPredictionJob.submit(\n",
        "    source_model=MODEL_ID,\n",
        "    input_dataset=f\"bq://{PROMPTS_TABLE}\",\n",
        "    output_uri_prefix=f\"bq://{text_generation_table}\",\n",
        ")\n",
        "\n",
        "# Poll until the batch prediction job completes.\n",
        "while not batch_job.has_ended:\n",
        "    batch_job.refresh()\n",
        "    print(f\"Batch job state: {batch_job.state}\")\n",
        "    time.sleep(30)\n",
        "print(f\"Batch job state: {batch_job.state}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTl8-Cbg7Ll5"
      },
      "source": [
        "### List sample of text generation results from BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0jHGtZEUK88"
      },
      "outputs": [],
      "source": [
        "text_generation_df = bpd.read_gbq(text_generation_table)\n",
        "for row in text_generation_df[\"response\"][:5]:\n",
        "    print(json.loads(row)[0][\"content\"][\"parts\"][0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q96WpoTw4Kr6"
      },
      "source": [
        "##Create Views in BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hVJ_n3P6AF4"
      },
      "source": [
        "### Create view of text generation results\n",
        "\n",
        "Run this only once to create the view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbT4qLbTQ7iD"
      },
      "outputs": [],
      "source": [
        "def create_text_generation_view(\n",
        "    text_generation_table_prefix: str, results_view: str\n",
        ") -> None:\n",
        "    \"\"\"Creates a view of text extraction results.\"\"\"\n",
        "\n",
        "    view = bigquery.Table(results_view)\n",
        "\n",
        "    view.view_query = rf\"\"\"\n",
        "      WITH t1 AS\n",
        "      (\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          JSON_EXTRACT(response, '$[0].content.parts[0].text') AS json_data\n",
        "        FROM `{text_generation_table_prefix}_*`\n",
        "      ),\n",
        "      t2 AS (\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          REGEXP_EXTRACT(json_data, r'```json(.*)```') AS f\n",
        "        FROM t1\n",
        "      ),\n",
        "      t3 AS(\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          REPLACE(f, '\\\\n', '') AS f\n",
        "        FROM t2\n",
        "      ),\n",
        "      t4 AS (\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          REPLACE(f, '\\\\\"', '\"') AS f\n",
        "        FROM t3\n",
        "      ),\n",
        "      t5 AS (\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          JSON_QUERY(f, '$.sport') AS f\n",
        "        FROM t4\n",
        "      ),\n",
        "      t6 AS (\n",
        "        SELECT\n",
        "          evaluation_id,\n",
        "          evaluation_ts,\n",
        "          prompt_text,\n",
        "          gcs_uri,\n",
        "          REPLACE(f, '\"', '') AS f\n",
        "        FROM t5\n",
        "      )\n",
        "\n",
        "      SELECT\n",
        "        evaluation_id,\n",
        "        evaluation_ts,\n",
        "        prompt_text,\n",
        "        gcs_uri,\n",
        "        f AS label\n",
        "      FROM t6\"\"\"\n",
        "\n",
        "    # Make an API request to create the view.\n",
        "    view = bq_client.create_table(view, exists_ok=False)\n",
        "    print(f\"Created {view.table_type}: {str(view.reference)}\")\n",
        "\n",
        "\n",
        "create_text_generation_view(\n",
        "    text_generation_table_prefix=TEXT_GENERATION_TABLE_PREFIX, results_view=RESULTS_VIEW\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcyIaLMC62rs"
      },
      "source": [
        "### Create view of experiment evaluation\n",
        "\n",
        "Run this only once to create the view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcZrWnI13H4F"
      },
      "outputs": [],
      "source": [
        "def create_evaluation_view(\n",
        "    evaluation_view: str, files_table: str, results_view: str\n",
        ") -> None:\n",
        "    \"\"\"Creates a view of experiment evaluation.\"\"\"\n",
        "\n",
        "    view = bigquery.Table(evaluation_view)\n",
        "\n",
        "    view.view_query = f\"\"\"\n",
        "      WITH t1 AS (\n",
        "        SELECT\n",
        "          e.evaluation_id,\n",
        "          e.evaluation_ts,\n",
        "          e.prompt_text,\n",
        "          f.path,\n",
        "          f.label,\n",
        "          e.gcs_uri,\n",
        "          f.label = e.label AS correct\n",
        "        FROM `{files_table}` f\n",
        "        JOIN `{results_view}` e\n",
        "          ON f.path = e.gcs_uri\n",
        "      )\n",
        "\n",
        "      SELECT\n",
        "        evaluation_id,\n",
        "        evaluation_ts,\n",
        "        prompt_text,\n",
        "        path,\n",
        "        label,\n",
        "        correct\n",
        "      FROM t1\"\"\"\n",
        "\n",
        "    # Make an API request to create the view.\n",
        "    view = bq_client.create_table(view, exists_ok=False)\n",
        "    print(f\"Created {view.table_type}: {str(view.reference)}\")\n",
        "\n",
        "\n",
        "create_evaluation_view(\n",
        "    evaluation_view=EVALUATION_VIEW, files_table=FILES_TABLE, results_view=RESULTS_VIEW\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01saqXPQbuIS"
      },
      "source": [
        "## Analyze results in BigQuery and Looker Studio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJvttnjyZxIs"
      },
      "source": [
        "### Copy a Looker Studio dashboard to analyze results\n",
        "\n",
        "1. Make a copy of this [Looker Studio dashboard](https://lookerstudio.google.com/reporting/caba1b62-2820-467a-bbe7-bd852d538de8/preview)\n",
        "1. Connect dashboard to your view"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "evaluating_prompts_at_scale_with_gemini_batch_prediction_api.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
